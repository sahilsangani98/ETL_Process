{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pandas==0.25.3\n",
    "# !conda install sqlalchemy\n",
    "# !conda install psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine # creates engine to connect DBAPI\n",
    "import psycopg2 # creates engine to connect with DBAPI (postgresql)\n",
    "from IPython.display import display\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store Accidental Death CSV into DataFrame\n",
    "csv_file1 = \"Accidental_Deaths_Data.csv\"\n",
    "accidental_death_df = pd.read_csv(csv_file1)\n",
    "accidental_death_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accidental_death_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clean data by dropping unnecessary columns\n",
    "accidental_death_df = accidental_death_df.drop(columns=['Address', 'Operations'])\n",
    "print(accidental_death_df.head())\n",
    "print(accidental_death_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidental_death_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Columns\n",
    "clean_accidental_death_df = accidental_death_df.rename(columns={\"Incident ID\":\"Incident_ID\", \"Incident Date\":\"Incident_Date\", \"State\":\"State\", \"City Or County\":\"City_or_County\", \"# Killed\":\"Num_Killed\", \"# Injured\":\"Num_Injured\"})\n",
    "clean_accidental_death_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Accidental Injury CSV into DataFrame\n",
    "csv_file2 = \"Accidental_Injury_Data.csv\"\n",
    "accidental_injury_df = pd.read_csv(csv_file2)\n",
    "accidental_injury_df.head()\n",
    "print(accidental_injury_df.isna().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# data cleaning\n",
    "accidental_injury_df = accidental_injury_df.drop(columns=['Address', 'Operations'])\n",
    "# print(accidental_injury_df.head())\n",
    "print(accidental_injury_df.isna().sum())\n",
    "\n",
    "# Rename columns\n",
    "clean_accidental_injury_df = accidental_injury_df.rename(columns={\"Incident ID\":\"Incident_ID\", \"Incident Date\":\"Incident_Date\", \"State\":\"State\", \"City Or County\":\"City_or_County\", \"# Killed\":\"Num_Killed\", \"# Injured\":\"Num_Injured\"})\n",
    "clean_accidental_injury_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store Mass_Shooting_Data into DataFrame\n",
    "csv_file3 = \"Mass_Shooting_Data.csv\"\n",
    "mass_shooting_df = pd.read_csv(csv_file3)\n",
    "display(mass_shooting_df.head())\n",
    "print(mass_shooting_df.isna().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# data cleaning\n",
    "mass_shooting_df = mass_shooting_df.drop(columns=['Address', 'Operations'])\n",
    "# print(accidental_injury_df.head())\n",
    "print(mass_shooting_df.isna().sum())\n",
    "\n",
    "# Rename columns\n",
    "clean_mass_shooting_df = mass_shooting_df.rename(columns={\"Incident ID\":\"Incident_ID\", \"Incident Date\":\"Incident_Date\", \"State\":\"State\", \"City Or County\":\"City_or_County\", \"# Killed\":\"Num_Killed\", \"# Injured\":\"Num_Injured\"})\n",
    "clean_mass_shooting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows in clean_mass_shooting_df: {}\".format(clean_mass_shooting_df.shape[0]))\n",
    "print(\"Number of rows in clean_accidental_injury_df: {}\".format(clean_accidental_injury_df.shape[0]))\n",
    "print(\"Number of rows in clean_accidental_death_df: {}\".format(clean_accidental_death_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging 3 datasets and removing dulicate entries based on Incident_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.merge -> Kind of joins -- Merge multiple dataframes (2)\n",
    "merge1 = pd.merge(clean_mass_shooting_df, clean_accidental_injury_df, on=\"Incident_ID\")\n",
    "display(merge1.head(5))\n",
    "\n",
    "print(\"\\nNumber of common entries: {}\".format(merge1.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "# clean_mass_shooting_df[ !(BigDF$ID %in% SmallDF$ID), ]\n",
    "\n",
    "# BigDF[ !(BigDF$ID %in% SmallDF$ID), ]\n",
    "# display(sub_result.head(5))\n",
    "# sub_result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = pd.merge(clean_mass_shooting_df, clean_accidental_death_df,on=\"Incident_ID\")\n",
    "display(merge2.head(5))\n",
    "print(\"\\nNumber of common entries: {}\".format(merge2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3 = pd.merge(clean_accidental_death_df, clean_accidental_injury_df, on=\"Incident_ID\")\n",
    "display(merge3.head(5))\n",
    "print(\"\\nNumber of common entries: {}\".format(merge3.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(merge1['Incident_ID'])\n",
    "# display(merge2['Incident_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # t1 = pd.merge(pd.merge(df1,df2,on='name'),df3,on='name')\n",
    "# t1 = pd.merge(pd.merge(clean_mass_shooting_df, clean_accidental_injury_df,how='left', on = 'Incident_ID'), \n",
    "#               clean_accidental_death_df, how='left', on = 'Incident_ID' )\n",
    "# display(t1.shape[0])\n",
    "# t.head(3)\n",
    "# # t2 = pd.merge(pd.merge(clean_accidental_injury_df, clean_accidental_death_df,how='left', on = 'Incident_ID'), \n",
    "# #               clean_mass_shooting_df, how='l', on = 'Incident_ID' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer_join = TableA.merge(TableB, how = 'outer', indicator = True)\n",
    "# anti_join = outer_join[~(outer_join._merge == 'both')].drop('_merge', axis = 1)\n",
    "\n",
    "outer_join = clean_accidental_injury_df.merge(clean_accidental_death_df, how = 'outer', indicator = True, on =\"Incident_ID\")\n",
    "outer_join.head(2)\n",
    "outer_join.shape[0]\n",
    "\n",
    "anti_join = outer_join[~(outer_join._merge == 'both')].drop('_merge', axis = 1)\n",
    "# outer_join.head(2)\n",
    "anti_join.shape[0]\n",
    "\n",
    "# t2 = pd.merge(pd.merge(clean_accidental_injury_df, clean_accidental_death_df,how='outer', on = 'Incident_ID'), \n",
    "#               clean_mass_shooting_df, how='outer', on = 'Incident_ID' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "list_2 = [\"a\", \"f\", \"c\", \"m\"] \n",
    "main_list = np.setdiff1d(list_2,list_1)\n",
    "main_list\n",
    "\n",
    "\n",
    "\n",
    "main_list = np.setdiff1d(clean_accidental_injury_df['Incident_ID'],clean_accidental_death_df['Incident_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df1[!(df1$name %in% df2$name),]\n",
    "# # df1[!(as.character(df1$jobId) %in% as.character(df2$name)), ]\n",
    "# t2 = clean_accidental_injury_df[!(as.numeric(clean_accidental_injury_df$Incident_ID) %in% as.numeric(clean_accidental_death_df$Incident_ID)),]\n",
    "# t2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_1_2 = df1.merge(df2, on=\"id\", how=\"left\", indicator=True)\n",
    "# df_1_2 = clean_mass_shooting_df.merge(clean_accidental_injury_df, how = 'left', indicator = True)\n",
    "# # display(df_1_2.head())\n",
    "# # df_1_2.shape[0]\n",
    "\n",
    "# df_1_not_2 = df_1_2[df_1_2[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "# display(df_1_not_2.shape[0]) # 23 columns removed\n",
    "\n",
    "# display(df_1_not_2.head())\n",
    "# # mass_shooting_df_u1 = df_1_not_2\n",
    "\n",
    "\n",
    "\n",
    "# df_1_3 = clean_mass_shooting_df.merge(clean_accidental_death_df, how = 'left', indicator = True)\n",
    "# df_1_not_3 = df_1_3[df_1_3[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "# display(df_1_not_3.shape[0]) # 11 columns removed\n",
    "# display(df_1_not_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading accidental deaths csv into database\n",
    "clean_accidental_death_df.to_sql(name='accidental_deaths', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# verifying data is loaded or not\n",
    "pd.read_sql_query('select * from accidental_deaths', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create Engine and connection to Database (DBAPI - PostgreSQL)\n",
    "'''\n",
    "        connection = psycopg2.connect(user = \"sysadmin\",\n",
    "                                  password = \"pynative@#29\",\n",
    "                                  host = \"127.0.0.1\",\n",
    "                                  port = \"5432\",\n",
    "                                  database = \"postgres_db\")\n",
    "'''\n",
    "try:\n",
    "    connection = psycopg2.connect(user = \"postgres\",\n",
    "                              password = \"root\",\n",
    "                              host = \"127.0.0.1\",\n",
    "                              port = \"5432\",\n",
    "                              database = \"Gun_Violence\") # returns database instance \n",
    "    cursor = connection.cursor() # returns cursor object that further used for manipulating databases with Python code\n",
    "    # Print PostgreSQL Connection properties\n",
    "    print ( connection.get_dsn_parameters(),\"\\n\")\n",
    "\n",
    "    # Print PostgreSQL version\n",
    "    cursor.execute(\"SELECT version();\") # takes SQL query as a parameter \n",
    "    record = cursor.fetchone() # returns result of query\n",
    "    print(\"You are connected to - \", record,\"\\n\")\n",
    "    \n",
    "    engine = create_engine('postgres://postgres:root@localhost:5432/Gun_Violence')\n",
    "    print(\"\\nEngine Created...!!!!\")\n",
    "    \n",
    "    conn = engine.connect()\n",
    "    print(\"\\nEngine Connected...!!!\")\n",
    "    \n",
    "except (Exception, psycopg2.Error) as error :\n",
    "    print (\"Error while connecting to PostgreSQL\", error)\n",
    "    \n",
    "# finally:\n",
    "#     #closing database connection.\n",
    "#         if(connection):\n",
    "#             cursor.close()\n",
    "#             connection.close()\n",
    "#             print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "#     engine = create_engine('postgres://postgres:root@localhost:5432/Gun_Violence')\n",
    "# conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading mass shootin csv into database \n",
    "clean_mass_shooting_df.to_sql(name='mass_shootings', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# verifying data is loaded or not\n",
    "pd.read_sql_query('select * from mass_shootings', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading accidental injury csv into database\n",
    "clean_accidental_injury_df.to_sql(name='accidental_injuries', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# verifying data is loaded or not\n",
    "pd.read_sql_query('select * from accidental_injuries', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to find some information from the combined dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Top 10 states in highest number of people killed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_Query = pd.read_sql_query('select * from mass_shootings', con=engine)\n",
    "retrived_mass_shooting_df = pd.DataFrame(SQL_Query)\n",
    "display(retrived_mass_shooting_df)\n",
    "Mass_Shootings_Kill_States = retrived_mass_shooting_df.drop([\"Incident_ID\",\"Num_Injured\", \"City_or_County\", \"Incident_Date\"], axis=1)\n",
    "Mass_Shootings_Kill_States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by='col1', ascending=False, na_position='first')\n",
    "mass_shooting_killing = Mass_Shootings_Kill_States.sort_values(by = 'Num_Killed', ascending= False)\n",
    "mass_shooting_killing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
